{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Bold;\f2\fmodern\fcharset0 Courier;
\f3\fswiss\fcharset0 Helvetica-BoldOblique;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red0\green0\blue0;\red11\green90\blue124;
\red254\green187\blue91;\red110\green5\blue2;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\csgray\c0\c0;\cssrgb\c0\c42931\c55996;
\csgenericrgb\c99608\c73333\c35686;\cssrgb\c51239\c6511\c0;}
\margl1440\margr1440\vieww21740\viewh27520\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs28 \cf0 UNDERSTANDING __init__.py file and base.py file\
\
\
Using __init__.py\
\
- this sets the entire folder as a module\
- ex: if __init__.py exists in folder learners, then learners can be imported as module in code: import learners\
\
Using base.py\
\
- holds base class BaseExperiment and class ExperimentDetails\
\

\f1\b TOP LEVEL CODE sequence
\f0\b0 \
- starting in run_experiments.py \
\cf2 \cb3       1 - we use base class 
\f2\fs26 ExperimentDetails 
\f0 from experiments folder that is now a module thanks to __init__.py
\f2 \

\f0\fs28 \cf0 \cb1       2 - call method run_experiment\
          2.i - in this method, we call the DT instance to use class method 
\f1\b perform
\f0\b0 ()\
      3 - DT instance then calls 
\f1\b experiments.perform_experiment
\f0\b0 () method\
          3.i experiments is a module thanks to __init__.py file\
      4 - in __init__.py we start at 
\f1\b perform_experiment
\f0\b0 \
         4.i call 
\f1\b basic_results
\f0\b0 ()\
              4.i.i. uses GridSearchCV immediately (this is cross validation)\
              4.i.ii. checks for best estimator\
              4.i.iii. generates plots ex: Confusion Matrix\
              4.i.iv. uses sklearn.model_selection 
\f1\b learning_curve
\f0\b0 () method\
              4.i.v. generates csv for curve_train_scores, curve_test_scores, generates plot for learning_curve\
          4.ii. return cv\
      5 - back in perform_experiment, we now define best_params from the returned CV computations\
         5.i. generate complexity curves by calling method 
\f1\b \cf2 \cb3 make_complexity_curve
\f0\b0 ()\cf0 \cb1 \
         5.ii. generate timing curve by calling method 
\f1\b \cf2 \cb3 make_timing_curve
\f0\b0 ()\cf0 \cb1 \
\
- in method run_experiment, we have access to experiment folder __init__.py file and perform()\
\

\f3\i\b __init.py__ methods
\f0\i0\b0 \
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf2 \cb3 - add_noise (not used)\
- 
\f1\b \cf4 perform_experiment
\f0\b0 \cf5 \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf2 \cb3 - make_timing_curve (used within 
\f1\b \cf4 perform_experiment
\f0\b0 \cf2 )\
- make_complexity_curve (used within 
\f1\b \cf4 perform_experiment
\f0\b0 \cf2 )\
- basic_results (used within 
\f1\b \cf4 perform_experiment
\f0\b0 \cf2 )\
- 
\f1\b \cf6 iteration_lc
\f0\b0 \cf2  (used within 
\f1\b \cf4 perform_experiment
\f0\b0 \cf2 )\
      \'97 balanced_accuracy (used within 
\f1\b \cf6 iteration_lc
\f0\b0 \cf2 )\
      \'97 f1_accuracy (used within 
\f1\b \cf6 iteration_lc
\f0\b0 \cf2 )\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf2 \cb3 \
\
How are these called?\
In order\
\
\'97 first method \'97 \
basic_results(clf, classes, training_x, training_y, test_x, test_y, params, clf_type=None, dataset=None,\
                  dataset_readable_name=None, balanced_dataset=False, best_params=None, seed=55, threads=1)\
\
clf is Pipeline(memory=None,\
     steps=[('Scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('DT', DTLearner(alpha=None, class_weight=None, criterion='entropy', max_depth=None,\
     max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0,\
     min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\
     min_weight_fraction_leaf=0.0, presort=False, random_state=1,\
     splitter='best'))]\
\
classes is 0, 1 (our categorial y data)\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf2 \cb3 training_x, training_y, test_x, test_y = the data splits\
\
clf_type is DT\
\
dataset: str of data type name\
\
balanced_dataset, boolean True or False\
\
seed, threads defined in run_experiments.py file\
\
\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97}